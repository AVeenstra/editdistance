% This is "bach-ref-2009.tex" Updated january 29th 2010.
% This file should be compiled with "sig-alternate-fixed.cls" January 2010.
% It is based on the ACM style "sig-alternate.cls"
% -------------------------------------------------------------------------
% This example file demonstrates the use of the 'sig-alternate-fixed.cls'
% V2.5 LaTeX2e document class file. It is for those submitting
% articles to the Twente Student Conference on IT. Both this file as the 
% document class file are based upon ACM documents.
%
% ----------------------------------------------------------------------------------------------------------------
% This .tex file (and associated .cls) produces:
%       1) The Permission Statement
%       2) The Conference (location) Info information
%       3) The Copyright Line TSConIT
%       4) NO page numbers
%       5) NO headers and/or footers
%
%
% Using 'sig-alternate.cls' you have control, however, from within
% the source .tex file, over both the CopyrightYear
% (defaulted to 200X) and the ACM Copyright Data
% (defaulted to X-XXXXX-XX-X/XX/XX).
% e.g.
% \CopyrightYear{2007} will cause 2007 to appear in the copyright line.
% \crdata{0-12345-67-8/90/12} will cause 0-12345-67-8/90/12 to appear in the copyright line.
%
% ---------------------------------------------------------------------------------------------------------------
% This .tex source is an example which *does* use
% the .bib file (from which the .bbl file % is produced).
% REMEMBER HOWEVER: After having produced the .bbl file,
% and prior to final submission, you *NEED* to 'insert'
% your .bbl file into your source .tex file so as to provide
% ONE 'self-contained' source file.
%

% refers to the cls file being used
\documentclass{sig-alternate-br}

\begin{document}
%
% --- Author Metadata here --- DO NOT REMOVE OR CHANGE 
\conferenceinfo{23$^{th}$ Twente Student Conference on IT}{June 22$^{nd}$, 2016, Enschede, The Netherlands.}
%\CopyrightYear{2010} % Allows default copyright year (200X) to be over-ridden - IF NEED BE.
%\crdata{0-12345-67-8/90/01}  % Allows default copyright data (0-89791-88-6/97/05) to be over-ridden - IF NEED BE.
% --- End of Author Metadata ---

\title{Edit distance on GPU clusters using MPI}
% In Bachelor Referaat at University of Twente the use of a subtitle is discouraged.
% \subtitle{[Instructions]}

%
% You need the command \numberofauthors to handle the 'placement
% and alignment' of the authors beneath the title.
%
% For aesthetic reasons, we recommend 'three authors at a time'
% i.e. three 'name/affiliation blocks' be placed beneath the title.
%
% NOTE: You are NOT restricted in how many 'rows' of
% "name/affiliations" may appear. We just ask that you restrict
% the number of 'columns' to three.
%
% Because of the available 'opening page real-estate'
% we ask you to refrain from putting more than six authors
% (two rows with three columns) beneath the article title.
% More than six makes the first-page appear very cluttered indeed.
%
% Use the \alignauthor commands to handle the names
% and affiliations for an 'aesthetic maximum' of six authors.
% Add names, affiliations, addresses for
% the seventh etc. author(s) as the argument for the
% \additionalauthors command.
% These 'additional authors' will be output/set for you
% without further effort on your part as the last section in
% the body of your article BEFORE References or any Appendices.

\numberofauthors{1} %  in this sample file, there are a *total*
% of EIGHT authors. SIX appear on the 'first-page' (for formatting
% reasons) and the remaining two appear in the \additionalauthors section.
%
\author{
% You can go ahead and credit any number of authors here,
% e.g. one 'row of three' or two rows (consisting of one row of three
% and a second row of one, two or three).
%
% The command \alignauthor (no curly braces needed) should
% precede each author name, affiliation/snail-mail address and
% e-mail address. Additionally, tag each line of
% affiliation/address with \affaddr, and tag the
% e-mail address with \email.
%
% 1st. author
\alignauthor Antoine Veenstra\\
       \affaddr{University of Twente}\\
       \affaddr{P.O. Box 217, 7500AE Enschede}\\
       \affaddr{The Netherlands}\\
       \email{a.j.veenstra@student.utwente.nl}
% 2nd. author
%\alignauthor 2nd Author\\
%      \affaddr{2nd author's affiliation}\\
%      \affaddr{1st line of address}\\
%      \affaddr{2nd line of address}\\
%      \email{2nd author's email address}
% 3rd. author
%\alignauthor 3rd Author\\
%      \affaddr{3rd author's affiliation}\\
%      \affaddr{1st line of address}\\
%      \affaddr{2nd line of address}\\
%      \email{3rd author's email address}
}
% There's nothing stopping you putting the seventh, eighth, etc.
% author on the opening page (as the 'third row') but we ask,
% for aesthetic reasons that you place these 'additional authors'
% in the \additional authors block, viz.
%\additionalauthors{Additional authors: John Smith (The
%Th{\o}rv{\"a}ld Group, email: {\texttt{jsmith@affiliation.org}})
%and Julius P.~Kumquat (The Kumquat Consortium, email:
%{\texttt{jpkumquat@consortium.net}}).}
%\date{30 July 1999}
% Just remember to make sure that the TOTAL number of authors
% is the number that will appear on the first page PLUS the
% number that will appear in the \additionalauthors section.

\maketitle
\begin{abstract}
In this paper, we describe how the edit distance problem can be distributed over a GPU-cluster using MPI and OpenCL.
The performance of the cluster will then be compared to that of a single device.
\end{abstract}

% A category with the (minimum) three required fields (NOT USED in Bachelor Referaat)
% \category{H.4}{Information Systems Applications}{Miscellaneous}
%A category including the fourth, optional field follows...
% \category{D.2.8}{Software Engineering}{Metrics}[complexity
% measures, performance measures]

\keywords{OpenCL, Edit distance problem, GPU-cluster, C++, case study, GPGPU program, MPI, Message Passing Interface, case study}

\section{Introduction}
As the amount of data increases the need for parallel computation does so too.
The edit distance problem is used in various fields of research\cite{Navarro:2001:GTA:375360.375365}.
Fields such as Computational Biology, Signal Processing, and Text Retrieval.
This algorithm has already been implemented on a single Graphics Processing Unit (GPU)\cite{Heus:GPGPU}, but to decrease the processing time even further a logical step is to increase the number of GPUs\cite{Cluster}.
These GPUs allow the processing of larger amounts of data in parallel than is possible on a CPU. 

The existing implementation of the edit distance problem uses a dynamic programming algorithm, which is well-suited for general-purpose computing on graphics processing units (GPGPU).
The implementation was written in C++ using OpenCL which can run on both NVIDIA and AMD GPUs.
An alternative would have been CUDA, which has been developed by NVIDIA and runs exclusively on NVIDIA GPUs.
OpenCL has been and will be chosen over CUDA in order to ensure compatibility with most types of GPUs.

To allow interaction between devices in a cluster a protocol is required.
One standard which has been around for years is the Message Passing Interface (MPI)\cite{MPI}.
This interface will be used to distribute the algorithm on multiple (multi-)GPU nodes.
A successful program using MPI and OpenCL has already been made\cite{Cluster}. 

By implementing the edit distance problem on a GPU-cluster instead of a single GPU the processing time could be reduced as the performance of a cluster exceeds that of a single unit\cite{Cluster}.
The goal of the research described in this paper is to implement the edit distance problem on a GPU-cluster using MPI.
This goal gives us the research question mentioned in the following section.

\section{Research questions}
The research question of this proposal is:

How much can the processing time needed to calculate the edit distance problem be reduced using a GPU cluster which uses MPI?

A possible division in subquestions is:
\begin{enumerate}
    \item How can the algorithm be divided in separate processes?
    \item How can the algorithm be run on multiple devices using MPI?
    \item What is the optimal number of GPUs when considering cost and efficiency?
\end{enumerate}

\section{Background}
\subsection{OpenCL}
OpenCL is a programming language which allows a developer to run a kernel on a GPU or CPU\cite{OpenCL}.
It is a low level programming language which can run on most GPUs and CPUs and allows general purpose parallel programming across both CPUs and GPUs.
The traditional CPU-based programming models do not allow the same complex vector operations as OpenCL offers without the need to translate their algorithms to a 3D graphics API such as OpenGL.
As mentioned before OpenCL is preferred over CUDA since the support of CUDA for GPUs and CPUs is limited to NVIDIA GPUs\cite{CUDA}.

\subsection{GPGPU programming}
GPGPU programming is the use of GPUs to handle computation which traditionally is done by CPUs.
The number of cores on a GPU is generally much higher than a CPU has, so a GPU can process more data in parallel.
OpenCL loads a kernel on every OpenCL device and a host program manages the execution of the kernels.
After a kernel has finished running the results are returned to the host program.
The kernel on every core is the same, so the only way to change the outcome of the program is to modify the input of the program.

\subsection{MPI}
MPI is a standard specification in communication between computers which enables parallel computing\cite{MPI}.
An implementation of specification is freely available and will be used in this project.
The implementation allows the transmission of multiple datatypes and messages between nodes.
It also provides a way to identify all the connected processes and assign an identifier to each process.
These features could help dividing the workload over all nodes.

\subsection{Edit distance}
The edit distance problem is way of measuring how much two strings differ from each other\cite{Navarro:2001:GTA:375360.375365}.
The distance between two strings is measured by operations like inserting, removing, replacing, and rearranging characters.
The complexity of the algorithm depends on what operations are allowed and the cost of these operations in the implementation.
For this project only inserting, removing, and replacing are considered.
These operations costs are $C_i$ (insertion), $C_d$ (deletion), and $C_r$ (replacement) for each operation is variable.

An example input is:
\begin{align*}
S_1 &= \text{Saturday}\\
S_2 &= \text{Sunday}\\
C_i &= 2\\
C_d &= 3\\
C_r &= 6
\end{align*}
With this given input the output of the program should be $11$.

\section{Related work}
\subsection{Edit distance problem on GPU}
As mentioned before the edit distance problem has already been implemented on a single GPU\cite{Heus:GPGPU}. This implementation also uses the operations insert, delete, and replace. This implementation will be improved if necessary and will probably be the base of the future implementation.

\subsection{Benchmark on a GPU-cluster}
This is an MPI-OpenCL implementation of the LINPACK benchmark which was run on a cluster containing 49 nodes, each node containing two eight-core CPUs and four GPUs\cite{i}.
The implementation achieves 93.69 Tflops, which is 46 percent of the theoretical peak.
It shows a successful implementation of MPI in combination with OpenCl, which is required in the future implementation of the edit distance algorithm.

\section{Method}
The research question is best answered with a comparison in time needed to compute the edit distance.
One possible way to measure the difference in time required is to calculate the edit distance of two large strings, possibly DNA sequences, is to calculate it on every node of the cluster individually and then as a cluster working together.
The average time every individual node requires can then be compared to the time taken by the cluster.
This test should be repeated with different sizes of clusters and different types of nodes to obtain reliable and realistic results.

One thing to consider is how to distribute the two strings, especially if they are quite large. A few distribution methods are:
\begin{enumerate}
    \item Saving the strings on the nodes before execution.
    \item Choosing a master node which distributes the string to its slave nodes.
    \item Hosting the strings on a separate server which does not take part in calculation of the edit distance.
\end{enumerate}
Options two and three are the most realistic options, as the distribution of the data would be part of the processing time. Option one on the other hand reduces the bottleneck create by the reading speed of the storage device, which allows comparison of the speed without taking into account the hardware storing the strings.

Option three will probably be used, since a device uploading the strings to a cluster could be a real live situation.

\section{Conclusions}
The possible answers to the research question can be divided in different ranges.
The first range is a negative time difference, which indicates the use of MPI, dividing the algorithm, or the use of a cluster in general is inefficient.

The next range is a difference almost equal to zero, which indicates that dividing the calculation gives too much overhead, leaving no room for significant improvements.

The third range is a difference up to $n$ times as fast as the single node implementation, where $n$ is the number of nodes in the cluster.
This would mean that dividing the computation over a cluster is more efficient than calculating it on a single node, but that the overhead still impacts the performance of the algorithm.
My hypothesis is that the result will be in this range.

The last range is the most improbable. It ranges from $n$ times as fast to infinity as fast, where $n$ is the number of nodes.
This would mean that the algorithm is more efficient as it is divided on multiple computers.
If, for example, the number of nodes is doubled the speed would more than double.
This would be strange since the processing power does not double.

%\balancecolumns
%\newpage

\bibliographystyle{abbrv}
\bibliography{sigproc}


\end{document}
