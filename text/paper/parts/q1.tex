\section{Dividing the algorithm} \label{q1}
To answer this question we must first explore the limitations and potential improvements of the previous implementation.
The limitations will then be discussed and solved if possible in the following subsections.
In the final subsection the algorithms used will be described.

\subsection{Original algorithm} \label{originalalg}
The algorithm of De Heus uses a dynamic programming solution \cite{Heus}.
In his paper he describes a way to distribute the computation on multiple work-groups of a GPU.
The dynamic programming algorithm fills a matrix with the following rules \cite{Jordan}:

\begin{equation} \label{eq1}
\begin{split}
H_{(-1,j)} & = j \\
H_{(i,-1)} & = i \\
H_{(i,j)} & = \min \begin{cases}
          \operatorname{H}_{(i-1,j)} + 1 \\
          \operatorname{H}_{(i,j-1)} + 1 \\
          \operatorname{H}_{(i-1,j-1)} + Score
\end{cases}
\end{split}
\end{equation}

where $Score$ is zero if the characters of the compared sequences at index $i$ and $j$ are equal; otherwise, $Score$ is one.

The value of $H_{(i,j)}$ depends on the cells $H_{(i-1,j)}$, $H_{(i,j-1)}$, and $H_{(i-1,j-1)}$.
This limits the use of parallelism to speed up the computation, but it leaves an opening nonetheless.
There is no dependency between cells $H_{(a,b)}$ if $a + b$ is constant.
The grey cells in \cref{diagonal} are such a group of cells which can be calculated in parallel.
Each diagonal is based on the previous two diagonals, because of the dependencies previously mentioned \cite{Meyers}.
There is no need to save diagonals prior to those two diagonals, so the implementation can discard the previous diagonals to save memory.

{\newcommand\C[0]{\cellcolor{gray}}
\begin{figure}[p]
\centering \large
\begin{tabular}{|c|c||c|c|c|c|c|c|} \hline
           &            & \textbf{k} & \textbf{i} & \textbf{t} & \textbf{t} & \textbf{e} & \textbf{n} \\ \hline
           & \textbf{0} & \textbf{1} & \textbf{2} & \textbf{3} & \textbf{4} & \textbf{5} & \textbf{6} \\ \hline \hline
\textbf{s} & \textbf{1} & 1          & 2          & 3          & 4          & \C         &            \\ \hline
\textbf{i} & \textbf{2} & 2          & 1          & 2          & \C         &            &            \\ \hline
\textbf{t} & \textbf{3} & 3          & 2          & \C         &            &            &            \\ \hline
\textbf{t} & \textbf{4} & 4          & \C         &            &            &            &            \\ \hline
\textbf{i} & \textbf{5} & \C         &            &            &            &            &            \\ \hline
\textbf{n} & \textbf{6} &            &            &            &            &            &            \\ \hline
\textbf{g} & \textbf{7} &            &            &            &            &            &            \\ \hline
\end{tabular}
\caption{Example matrix} \label{diagonal}
\end{figure}
}

\subsection{Partitioning the algorithm} \label{partitioning}
With larger sequences the diagonal becomes too large to calculate in one iteration on a GPU.
Dividing the matrix vertically allows one to split the calculation in manageable parts.
These parts will be called pillars.
Each pillar requires the right most column of the previous pillar due to the dependencies of each cell.
This means the other columns can be discarded to save memory.

\begin{figure}[p]
    \centering
    \includesvg[width=0.99\linewidth]{cols2}
    \caption{Partitioning of the matrix} \label{division}
\end{figure}

Each of the pillars mentioned above can be split in blocks.
Blocks $A$ to $D$, $E$ to $H$, and $I$ to $L$ in \cref{division} are such a partitioning.
The dependencies of the individual cells are inherited by the individual blocks.
Just like the cells the blocks can also be calculated in parallel if they are not dependent of one another.
Block $D$ and $F$ are such blocks as they only require block $B$ and $C$.
With larger sequences the number of independent blocks becomes more significant.
As a result, the calculation of multiple blocks in parallel becomes more attractive.

If the blocks where squares, as De Heus suggested \cite{Heus}, the amount of cells processed in parallel would start at $1$, continue to $width$, and go back to $1$.
The amount of cells processed increases or decreases by 1 every iteration, so the average amount of cells processed is approximately $width/2$ cells processed in parallel.
Blocks like $B$ and $K$ on the other hand have an average amount of cells processed in parallel of exactly $width$.
The only disadvantage of this approach is that the top and bottom of each pillar blocks like $A$ and $D$ exist, but the overall performance is still better.
Therefore, the pillars will be constructed diagonally to optimise the amount of cells processed in parallel at any given time.

\subsection{Storing the diagonals} \label{section:diagonal}
As mentioned before, two diagonals are required to calculate the following diagonal.
Unfortunately, OpenCL offers no support for an array of arrays, so either the two diagonals must be saved in separate variables or they must be combined in one larger array.
Using two variables limits the freedom while implementing the algorithm as the rows must be swapped after each iteration.
Using a single combined array requires the calculation of indices each time the algorithm accesses the array.
The two solutions are not significantly different, so another factor should be considered before opting for one of the two solutions.
The most common blocks are shaped like $B$, $C$, $F$, etc.
Therefore, the rest of this section will only consider the algorithm required to process those blocks.

\begin{figure}[p]
    \centering
    \subfloat[][Input]{\label{twovarsinput}\includesvg[width=0.45\linewidth]{twovarsinput}}
    \subfloat[][Output]{\label{twovarsoutput}\includesvg[width=0.45\linewidth]{twovarsoutput}}
    \caption{The two variable implementation} \label{twovars}
\end{figure}

An input the algorithm for processing a block should digest is the left column and it should output the right most column of the block.
The two diagonals should evolve, but the size should stay constant.
In the two variables solution the column values could be divided between and appended to the two diagonals.
This requires some preprocessing as the even indices of the column should be appended to one diagonal and the odd indices to the other as shown in \cref{twovarsinput}.
Some post-processing is also required to retrieve the column after processing as shown in \cref{twovarsoutput}.
A solution to this problem is to transfer the parts of diagonals a and b as is.
The pre- and post-processing steps cancel each other out, so there is no need to do so.

\begin{figure}[ht]
    \centering
    \includesvg[width=0.65\linewidth]{singlevar}
    \caption{Computation with a single array} \label{singlevar}
\end{figure}

The digestion of the input and the supplying of output is comparable in the single array solution.
\Cref{singlevar} shows the evolution of the single array throughout the computation of a block.
The block used in this figure is block $B$ from \cref{division}, which is four columns wide and consists of seven iterations.
There is no advantage or disadvantage on which end the input and output are stored.
The blocks of memory can be transferred to another process as is, just as in the two variable solution.

We can conclude that there are no significant advantages or disadvantages to either solution.
The single variable solution is only slightly more attractive since there is one less variable to worry about.
Therefore, the single variable solution will be chosen in the algorithms mentioned in \cref{algorithms}.

The calculation of indices depends on the iteration count of the algorithm.
The formula used to get the index of the diagonal to change is $i + n \cdot 2 + 1$ where $i$ is the number of iterations completed and $n$ is the index of the cell in the diagonal.
The index of the cell above the targeted cell is determined by subtracting $1$ from the index of the targeted cell and the index of the cell to the left of the targeted cell is determined by adding $1$ to the index of the targeted cell.
This means that the cells used by a thread are three consecutive cells of which the middle one will be replaced with the calculated value.
This can be seen in \cref{singlevar}, where three consecutive cells calculate the result of the middle cell.
This figure also shows how the dependency on the iteration count influences the indices of the targeted cells.

A visual representation of which cells are stored in the array can be found twice in \cref{division} as $D1$ and $D2$.
Lines $D1$ and $D2$ cross all the cells stored in the array at one point in the algorithm.
The arrows go from the targeted cells to the cell for which the values are calculated during the next iteration.
The arrows next to $D1$ represent the third iteration and the arrows next to $D2$ represent the last iteration.
The top cell of the lines are stored on index zero and the bottom cell is stored in the last cell of the array.
This direction has been chosen to make debugging easier as the resulting column will be in the first cells of the diagonal after the run, making them easier to find and compare to known results.
There is no other advantage or disadvantage if the result is stored the other way around.
\Cref{singlevar} also shows this same orientation.
The input is equivalent to the left most column as seen in $D1$ and the output equivalent to the right most column in $D2$.

%As can be seen in the figure the total size of the diagonal is $total_block_height + width + 1$.
%In this case the $total_block_height$ is $19$ the $width$ is $10$, so the size of the diagonal is $30$.

%Note that those diagonals can not be in the same state at the same time as the diagonal of block $E$ depends on block $B$.


\subsection{Constructing the initial diagonals} \label{section:initial}
Now that the storage of the diagonals has been set the array has to be initiated at the beginning of the pillar.
In \cref{tstart} an example of a starting block is shown which is a zoomed in version of block $A$ in \cref{division}, but also applies to block $E$.
The width of the pillars is $4$, so the block is a triangle of $3$ by $3$ cells.

In \cref{tstart} column \textbf{A} can be copied from the previous pillar and row \textbf{0} can be calculated by adding the offset of the pillar to the cell.
In \cref{start} the array containing the diagonals and its transformation is shown.
The coordinates in the \cref{start} correspond to the coordinates in \cref{tstart}.
Each iteration is numbered and the first iteration of the following block is shown at the bottom.

{
\begin{figure}[t]
\newcommand\C[0]{\cellcolor{gray}}
\newcommand{\mc}[3]{\multicolumn{#1}{#2}{#3}}
\begin{center} \large
\begin{tabu}{|c||c|[1.5pt]cccc|[1.5pt]c}\cline{2-7} \hline
           & \mc{1}{c|}{\textbf{A}}  & \mc{1}{c|}{\textbf{B}} & \mc{1}{c|}{\textbf{C}} & \mc{1}{c|}{\textbf{D}} & \mc{1}{c|}{\textbf{E}}& $\cdots$ \\\hline \hline
\textbf{0} & A0          & \mc{1}{l|}{B0}         & \mc{1}{l|}{C0}         & \mc{1}{l|}{D0}         & E0        & $\cdots$ \\\tabucline[1.5pt]{-}
\textbf{1} & A1          & \mc{1}{l|}{B1}         & \mc{1}{l|}{C1}         & \mc{1}{l|}{D1}         & \C        & \\\cline{1-5}\cline{7-7}
\textbf{2} & A2          & \mc{1}{l|}{B2}         & \mc{1}{l|}{C2}         & \C                     & \C        & \\\cline{1-4}\cline{7-7}
\textbf{3} & A3          & \mc{1}{l|}{B3}         & \C                     & \C                     & \C        & \\\cline{1-3}\cline{7-7}
\textbf{4} & A4          & \C                     & \C                     & \C                     & \C        & \\\cline{1-2}\cline{7-7}
$\vdots$   & $\vdots$    & \mc{4}{c|[1.5pt]}{\C Block B}                                                              & $\ddots$ \\\cline{1-2}
\end{tabu}
\end{center}
\caption{Block $A$ zoomed in} \label{tstart}
\end{figure}
}

\begin{figure}[t]
    \centering
    \includesvg[width=0.8\linewidth]{start}
    \caption{Computation of the starting block} \label{start}
\end{figure}

\cref{start} resembles to \cref{singlevar}.
Both share the same property of having three consecutive cells defining the middle cell.
The obvious difference being the amount of cell being processed each iteration.
In the following section you will find the algorithm to compute this block.

\input{parts/alg_block}

\subsection{Computation of the last block} \label{section:lastblock}
At the bottom of every pillar there is a block with a flat base.
In \cref{division} $D$, $H$, and $L$ are such blocks.
If the same method as in \cref{singlevar} is used the array of diagonals will go out of bounds.
However, this poses no problem as both the result and the output column are independent of the cells below it.
Thus blocks $D$, $H$, and $L$ will be treated the same way as blocks like $B$.
The only difference is the number of iterations required to get the right most column of the block.

\subsection{The OpenCL algorithms} \label{algorithms}
\cref{division} shows three kinds of blocks.
How blocks like $A$, $E$, and $I$ are computed is explained in \cref{section:initial} and can be seen in \cref{start}.
How blocks like $B$, $C$, $F$, $G$, $J$, $K$, and $E$ are computed is explained in \cref{section:diagonal} and can be seen in figures \ref{division} and \ref{twovars}.
Blocks like $D$, $H$, and $L$ are computed like block $B$ as explained in \cref{section:lastblock}, so they will not be treated differently.
\Crefrange{block}{fill_column} contain JML specifications in green, which will be discussed in \crefrange{ver:block}{ver:fill_column}.

\subsubsection{Algorithm to compute standard blocks}
\Cref{block} is used to handle blocks like $B$, and $D$.
Variable $d$ contains the diagonals as explained in \cref{section:diagonal}.
The $id$ is the id of the thread.
OpenCL allows multiple threads to execute the same algorithm in parallel.
The id of the thread is a unique number from zero till the number of threads.
This id is used to identify which column of the block the thread is to process.
Variable $width$ is the width of the block.
The width of the block is equal to the amount of threads OpenCL is using.
Variable $height$ is the number of iterations to be executed.
There is no limit to this number apart from the length of sequence $b$, as it is useless to compute more rows than present.
Variables $s_a$ and $s_b$ are parts of sequences $a$ and $b$ respectively.
The size of $s_a$ is equal to the $width$.
The size of $s_b$ is equal to the total height of the block, so this is equal to $height + width - 1$.

As seen on line \ref{block:a} of \cref{block} each thread picks a column according to the following formula: $width - 1 - id$.
If the $id$ had been used to pick a column the equations on lines \ref{block:ifscorebegin} and \ref{block:x} would be ``$a = s_b[width - id + i]$'' and ``$x \gets width - id + i$'' respectively, so there is no significant difference.
%Every iteration of the for loop on lines 3 to 16 consists of two parts.
%In the first part from lines 5 to 13 only read operations occur and in the second part, which is line 15, only write operations occur. \todo{correct}

Each iteration is separated by a \Call{barrier}{\relax} operation on line \ref{block:barrier}.
It guarantees that every thread is at the same point in the program before any can continue.
As $x$ is computed with the $id \cdot 2$, the $x$s at every iteration always differs with at least 2 between threads.
This means that no thread can read a cell while another is writing in the same memory, thus guaranteeing that no memory inconsistencies occur during operation.

\input{parts/alg_begin}

\subsubsection{Algorithm of initial blocks}
\Cref{begin} is used to handle blocks like $A$, $E$, and $I$.
Variables $id$, $width$, $s_a$, $s_b$, and $d$ are the same as in \cref{block}.
Variable $\mathit{offset}_a$ is the offset of the pillar relative to sequence $a$, where the first element of the sequence is zero.

Lines \ref{begin:fillbegin} to \ref{begin:fillend} fill the top row, which is row \textbf{0} in \cref{tstart}.
Since the row is one cell wider than the width, one thread has to set two cells.
On line \ref{begin:a} the character of the column being computed is loaded.
Each thread loads the character at index $id$.
If the index would be $width - id - 1$ the equations on lines \ref{begin:ifbegin}, \ref{begin:scoreifbegin}, and \ref{begin:x} would be along the lines of ``$width - id - 1 \leq i$'', ``$a = s_b[i-(width-id-1)]$'', and ``$x \gets i + width - (width - id - 1) \cdot 2$''.
These equations are longer and thus more susceptible to bugs.

Lines \ref{begin:forbegin} through \ref{begin:forend} are equivalent to lines \ref{block:forbegin} to \ref{block:forend} in \cref{block}.
The only difference between the two loops is that not all the threads calculate a new value in \cref{begin} as can be seen in \cref{start}.
The if statement on line \ref{begin:ifbegin} ensures that.
%Both the branches of the if statement contain a \Call{barrier}{\relax} statement so that all threads encounter the same amount of those statements.
%Where this not the case the behaviour of the algorithm would be undefined.

\input{parts/alg_fill_column}

\subsubsection{Algorithm of initial column}
There is only one column unaccounted for and that is the initial column as indicated in \cref{division}.
\Cref{fill_column} does that while taking into the account the structure of the variable containing the diagonals.
The variables $id$, $width$, $height$, and $d$ are the same as in Algorithms \ref{block} and \ref{begin}.
The variable $\mathit{offset}_b$ is the offset of the block relative to sequence $b$, where the first element of the sequence is zero.
Line \ref{fill_column:total_size} calculates the total size of the diagonal and line \ref{fill_column:i} calculates the starting index to fill.
The while loop on lines \ref{fill_column:whilebegin} to \ref{fill_column:whileend} fills each cell of the diagonal while respecting the offset of b.
There are no \Call{barrier}{\relax} statements in this algorithm as the threads only write to the memory.

\subsubsection{Conclusion}
With these three algorithms and the exchange of columns as described in \cref{partitioning} the edit distance between two sequences of arbitrary sizes can be computed.
The division in blocks as shown in \cref{division} allows for multiple process to work on the calculation in parallel.
This answers the fist subquestion as stated in \cref{questions}.

